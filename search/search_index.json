{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Here is a skim of this website: DEEP LEARNING Notes on RNN REGULARIZATION Dropout Method","title":"Home"},{"location":"#deep-learning","text":"Notes on RNN","title":"DEEP LEARNING"},{"location":"#regularization","text":"Dropout Method","title":"REGULARIZATION"},{"location":"contact/","text":"Hey, visitor! \\alpha\\beta\\rho\\alpha\\chi\\alpha\\delta\\alpha\\beta\\rho\\alpha! Welcome to my website! I'm now a student @NEU(CN). You can reach me at lintongmao@outlook.com.","title":"Contact"},{"location":"dropout/","text":"1. What is dropout? Dropout is a simple and powerful regularization method used in modern neural networks. The key idea is to randomly drop units (along with their connections) from the neural network during training with a probability p . Figure 1 illustrates how dropout is applied to a standard neural network (when training). 2. NOTE: TEST-TIME DROPOUT The basic idea of this mechanism is very simple. But, do note that after a network with dropout is trained, i.e., when testing a network, the same dropout mechanism should not be applied to the network any more, for we want a robust network instead of a reduced one. we can't simply drop the dropout mechanism as well, since that will cause a significant difference in the outputs of the training model and the model being tested. A proper way is to use \"a single unthinned network that has smaller weights\", i.e., we multiply each of a layer's input (or equivalently, the outputs of the previous layer) with the probability p . Formally, for a network layer \\mathbf{y} = f(W\\mathbf{x}+\\mathbf{b}) , let \\mathbf{x}\\in \\mathbb{R}^d , the output after dropout is applied is given by d(\\mathbf{x}) = \\begin{cases} \\mathbf{m}\\odot \\mathbf{x}, &\\text{during training}\\\\ p\\mathbf{x}, &\\text{during testing} \\end{cases} \\mathbf{y} = f(Wd(\\mathbf{x})+\\mathbf{b}) where \\mathbf{m}\\in\\{0,1\\}^d is a dropout mask that is generated using a Bernoulli distribution of probability p . In modern deep learning tools like pytorch in which dropout is already integrated, such changes can be easily achieved by some simple \"switch\", for example, in pytorch, the two different ways of applying dropout can be done by model.train() and model.eval() . 3. Dropout is great. Dropout has proven to be a very effective regularization method, that is, it prevents neural networks, especially the \"deep\" ones, from overfitting. Moreover, it boosts the training process of a model. Srivastava et al. experimented this approach on many benchmark datasets and the results showed that the models applied with dropout not only trained faster but achieved less error rates than regular models. For more details, please refer to this paper: Srivastava et al. , 2014 . 3. Why is dropout effective? To be continued, soon. 4. When & How should dropout be used? Despite it being powerful in regularizing a deep neural model, the dropout method has its limits. Chiyuan Zhang et al., 2017 showed that dropout is not effective in CNN when the data are corrupted. As far as I know, dropout is, generally, applied to the feedforward connections in a model. p is normally set to 0.5 - 0.8. And, do not apply to a network dropout method and batch normalization simultaneously. This has been experimented and proved to be a bad thing to do, by Xiang Li et al., 2018 5. For further study, you can refer to: \u300a\u795e\u7ecf\u7f51\u7edc\u4e0e\u6df1\u5ea6\u5b66\u4e60\u300b Srivastava et al. , Dropout: A simple way to prevent neural networks from overfitting.","title":"Dropout"},{"location":"dropout/#1-what-is-dropout","text":"Dropout is a simple and powerful regularization method used in modern neural networks. The key idea is to randomly drop units (along with their connections) from the neural network during training with a probability p . Figure 1 illustrates how dropout is applied to a standard neural network (when training).","title":"1. What is dropout?"},{"location":"dropout/#2-note-test-time-dropout","text":"The basic idea of this mechanism is very simple. But, do note that after a network with dropout is trained, i.e., when testing a network, the same dropout mechanism should not be applied to the network any more, for we want a robust network instead of a reduced one. we can't simply drop the dropout mechanism as well, since that will cause a significant difference in the outputs of the training model and the model being tested. A proper way is to use \"a single unthinned network that has smaller weights\", i.e., we multiply each of a layer's input (or equivalently, the outputs of the previous layer) with the probability p . Formally, for a network layer \\mathbf{y} = f(W\\mathbf{x}+\\mathbf{b}) , let \\mathbf{x}\\in \\mathbb{R}^d , the output after dropout is applied is given by d(\\mathbf{x}) = \\begin{cases} \\mathbf{m}\\odot \\mathbf{x}, &\\text{during training}\\\\ p\\mathbf{x}, &\\text{during testing} \\end{cases} \\mathbf{y} = f(Wd(\\mathbf{x})+\\mathbf{b}) where \\mathbf{m}\\in\\{0,1\\}^d is a dropout mask that is generated using a Bernoulli distribution of probability p . In modern deep learning tools like pytorch in which dropout is already integrated, such changes can be easily achieved by some simple \"switch\", for example, in pytorch, the two different ways of applying dropout can be done by model.train() and model.eval() .","title":"2. NOTE: TEST-TIME DROPOUT"},{"location":"dropout/#3-dropout-is-great","text":"Dropout has proven to be a very effective regularization method, that is, it prevents neural networks, especially the \"deep\" ones, from overfitting. Moreover, it boosts the training process of a model. Srivastava et al. experimented this approach on many benchmark datasets and the results showed that the models applied with dropout not only trained faster but achieved less error rates than regular models. For more details, please refer to this paper: Srivastava et al. , 2014 .","title":"3. Dropout is great."},{"location":"dropout/#3-why-is-dropout-effective","text":"To be continued, soon.","title":"3. Why is dropout effective?"},{"location":"dropout/#4-when-how-should-dropout-be-used","text":"Despite it being powerful in regularizing a deep neural model, the dropout method has its limits. Chiyuan Zhang et al., 2017 showed that dropout is not effective in CNN when the data are corrupted. As far as I know, dropout is, generally, applied to the feedforward connections in a model. p is normally set to 0.5 - 0.8. And, do not apply to a network dropout method and batch normalization simultaneously. This has been experimented and proved to be a bad thing to do, by Xiang Li et al., 2018","title":"4. When &amp; How should dropout be used?"},{"location":"dropout/#5-for-further-study-you-can-refer-to","text":"\u300a\u795e\u7ecf\u7f51\u7edc\u4e0e\u6df1\u5ea6\u5b66\u4e60\u300b Srivastava et al. , Dropout: A simple way to prevent neural networks from overfitting.","title":"5. For further study, you can refer to:"},{"location":"rnn/","text":"This article contains digests from: \u300a\u795e\u7ecf\u7f51\u7edc\u4e0e\u6df1\u5ea6\u5b66\u4e60\u300b The Unreasonable Effectiveness of Recurrent Neural Networks 1 What is RNN? Recurrent Neural Network is a class of neural networks with self-feedback neurons that are capable of handling sequences of variable-length. The figure below shows a typical RNN architecture. Given a sequence of inputs \\mathbf{x}_{1:T}=(\\mathbf{x}_1, \\mathbf{x}_2,\\cdots,\\mathbf{x}_T) , the activation \\mathbf{h}_t (namely, the hidden state at time t ) is given by \\mathbf{h}_t = f(\\mathbf{h}_{t-1}, \\mathbf{x}_t) where \\mathbf{h}_0=\\mathbf{0} and f(\\cdot) is a non-linearity (a non-linear function of a feed-forward net). 2 Variations of RNN 2.1 Vanilla RNN / Simple Recurrent Network (SRN) In a Simple Recurrent Network, \\mathbf{h}_t is updated by \\mathbf{h}_t = f(U\\mathbf{h}_{t-1} + W\\mathbf{x}_t + \\mathbf{b}) where U is a state-state weight matrix, W is a state-input weight matrix, and \\mathbf{b} is a bias vector. Theoretically, this model is capable of modeling any non-linear dynamical system. However, it suffers from the problems of gradient vanishing and gradient exploding (For details of how, refer to section 6.5 of this book ) and thus can't really model dependency over a long range of a sequence, which is often called Long-Term Dependencies Problem . 2.2 Long Short-Term Memory (LSTM) Several solutions can be applied to avoid the problem above. To avoid gradient from exploding, we can use weight decay or gradient clipping . To avoid gradient from vanishing, apart from applying certain optimization techniques, we can modify the model further. A simple thought is to apply a mechanism very similar to Residual Networks, \\mathbf{h}_t = \\mathbf{h}_{t-1} + g(\\mathbf{x}_t, \\mathbf{h}_{t-1};\\theta) where g(\\cdot) is a non-linearity (for details, again, refer to section 6.5 of this book ). Such a model still suffers from the gradient vanishing problem and the memory capacity problem, i.e., to some point \\mathbf{h}_t can no longer store much informations. Gated RNNs are an elegant modification of vanilla RNNs. One such example is LSTM, in which \\mathbf{h}_t is updated by \\begin{equation}\\begin{split} \\mathbf{c}_t &= \\mathbf{f}_t\\odot \\mathbf{c}_{t-1} + \\mathbf{i}_t\\odot \\tilde{\\mathbf{c}}_t\\\\ \\mathbf{h}_t &= \\mathbf{o}_t\\odot\\tanh(\\mathbf{c}_t) \\end{split}\\end{equation} where \\mathbf{c}_t is the internal state for linear information passing ( \\mathbf{c} is short for memory cell ), {f}_t , \\mathbf{i}_t and \\mathbf{o}_t are three gates used to control the flow of information, \\odot is element-wise production, \\tilde{\\mathbf{c}}_t is the candidate state , which is given by \\tilde{\\mathbf{c}}_t = \\tanh(U_c\\mathbf{h}_{t-1} + W_c\\mathbf{x}_t + \\mathbf{b}_c) The three gates are used in the following manner: forget gate \\mathbf{f}_t controls how much information should be discarded from the previous internal state \\mathbf{c}_{t-1} input gate \\mathbf{i}_t controls how much information should be stored from the candidate state \\tilde{\\mathbf{c}}_t output gate \\mathbf{o}_t controls how much information should be transferred from the internal state \\mathbf{c}_{t} to external state \\mathbf{h}_{t} The values of the three gates are given by \\begin{equation}\\begin{split} \\mathbf{f}_t &= \\sigma(U_f\\mathbf{h}_{t-1} + W_f\\mathbf{x}_t + \\mathbf{b}_f)\\\\ \\mathbf{i}_t &= \\sigma(U_i\\mathbf{h}_{t-1} + W_i\\mathbf{x}_t + \\mathbf{b}_i)\\\\ \\mathbf{o}_t &= \\sigma(U_o\\mathbf{h}_{t-1} + W_o\\mathbf{x}_t + \\mathbf{b}_o) \\end{split}\\end{equation} where \\sigma(\\cdot) is a Logistic function. P.S. In RNNs, \\mathbf{h} stores information about history inputs. In SRNs, \\mathbf{h} is rewritten at every time step t , thus can be perceived as a short-term memory. On the other hand, in LSTM, the memory cell \\mathbf{c} stores history information for some time steps (controlled by forget gate), thus can be seen as a short-term memory that lasts longer than \\mathbf{h} . This is how the name \"Long Short-term Memory\" comes about. 2.3 Gated Recurrent Unit (GRU) Gated Recurrent Unit is another RNN that uses gating mechanism. However, it does not introduce an extra memory cell. In GRU, \\mathbf{h}_t is updated by \\mathbf{h}_t = \\mathbf{z}_t\\odot\\mathbf{h}_{t-1} + (1-\\mathbf{z}_t)\\odot \\tilde{\\mathbf{h}}_t where \\mathbf{z}_t\\in [0,1] , called update gate, is computed by \\mathbf{z}_t = \\sigma(U_z\\mathbf{h}_{t-1} + W_z\\mathbf{x}_t + \\mathbf{b}_z) and, \\tilde{\\mathbf{h}}_t is computed by \\begin{equation}\\begin{split} \\tilde{\\mathbf{h}}_t &= \\tanh(U_h(\\mathbf{r}_t\\odot\\mathbf{h}_{t-1}) + W_h\\mathbf{x}_t + \\mathbf{b}_h)\\\\ \\mathbf{r}_t &= \\sigma(U_r\\mathbf{h}_{t-1} + W_r\\mathbf{x}_t + \\mathbf{b}_r) \\end{split}\\end{equation} where \\mathbf{r}_t\\in [0,1] , called reset gate, controls how much the candidate state \\tilde{\\mathbf{h}}_t depends on the previous state \\mathbf{h}_{t-1} . Intuitively, the GRU uses only one gate, as opposed to two in LSTM, to control the balance between the operations of forget and input , making it a simpler network than LSTM. 3 What can RNNs do? What exactly is a recurrent network capable of? 3.1 It can handle sequences. A glaring limitation of Vanilla Neural Networks (and also Convolutional Networks) is that their API is too constrained: they accept a fixed-sized vector as input (e.g. an image) and produce a fixed-sized vector as output (e.g. probabilities of different classes). P.S. Vanilla means \"ordinary\" or \"plain\" , not a flavor of dessert. Here it means ordinary neural nets like BPNN, MLP; likewise, vanilla RNNs means ordinary RNNs. The above picture shows some situations for a deep learning system to model. The leftmost subfigure illustrates the situation where both the input and the output are fixed-sized. This can be done without RNNs. The other subfigures show some more common situations, where a system has: sequence output (image captioning), sequence input (text sentiment classification), asynced sequence input and output (machine translation), and synced sequence input and output (POS tagging and NER). RNNs combine the input vector with their state vector with a fixed (but learned) function to produce a new state vector. This can in programming terms be interpreted as running a fixed program with certain inputs and some internal variables. Viewed this way, RNNs essentially describe programs . RNNs are Turing-Complete in the sense that they can to simulate arbitrary programs (with proper weights) . P.S. In Siegelmann and Sontag, 1991 , the authors models a recursive net with continuous-valued neurons as a dynamical system and remark that not only can one simulate a processor net with a Turing machine, but any function computable by a Turing machine can be computed by a processor net. The paper shows that a universal Turing machine can be simulated by a finite neural network made up of sigmoidal neurons. If training vanilla neural nets is optimization over functions, training recurrent nets is optimization over programs. 3.2 It excels at handling non-sequential data Even if the inputs/outputs are fixed vectors, it is still possible to use this powerful formalism to process them in a sequential manner. The following picture illustrates a recurrent network that generates images of digits by learning to sequentially add color to a canvas ( Gregor et al. ) In doing this, you\u2019re learning stateful programs that process your fixed-sized data , as opposed to merely learning a mapping between the input and the output. 4 Conclusion RNNs are powerful. For further study, please refer to the materials listed at the top of this page.","title":"Notes on RNN"},{"location":"rnn/#1-what-is-rnn","text":"Recurrent Neural Network is a class of neural networks with self-feedback neurons that are capable of handling sequences of variable-length. The figure below shows a typical RNN architecture. Given a sequence of inputs \\mathbf{x}_{1:T}=(\\mathbf{x}_1, \\mathbf{x}_2,\\cdots,\\mathbf{x}_T) , the activation \\mathbf{h}_t (namely, the hidden state at time t ) is given by \\mathbf{h}_t = f(\\mathbf{h}_{t-1}, \\mathbf{x}_t) where \\mathbf{h}_0=\\mathbf{0} and f(\\cdot) is a non-linearity (a non-linear function of a feed-forward net).","title":"1 What is RNN?"},{"location":"rnn/#2-variations-of-rnn","text":"","title":"2 Variations of RNN"},{"location":"rnn/#21-vanilla-rnn-simple-recurrent-network-srn","text":"In a Simple Recurrent Network, \\mathbf{h}_t is updated by \\mathbf{h}_t = f(U\\mathbf{h}_{t-1} + W\\mathbf{x}_t + \\mathbf{b}) where U is a state-state weight matrix, W is a state-input weight matrix, and \\mathbf{b} is a bias vector. Theoretically, this model is capable of modeling any non-linear dynamical system. However, it suffers from the problems of gradient vanishing and gradient exploding (For details of how, refer to section 6.5 of this book ) and thus can't really model dependency over a long range of a sequence, which is often called Long-Term Dependencies Problem .","title":"2.1 Vanilla RNN / Simple Recurrent Network (SRN)"},{"location":"rnn/#22-long-short-term-memory-lstm","text":"Several solutions can be applied to avoid the problem above. To avoid gradient from exploding, we can use weight decay or gradient clipping . To avoid gradient from vanishing, apart from applying certain optimization techniques, we can modify the model further. A simple thought is to apply a mechanism very similar to Residual Networks, \\mathbf{h}_t = \\mathbf{h}_{t-1} + g(\\mathbf{x}_t, \\mathbf{h}_{t-1};\\theta) where g(\\cdot) is a non-linearity (for details, again, refer to section 6.5 of this book ). Such a model still suffers from the gradient vanishing problem and the memory capacity problem, i.e., to some point \\mathbf{h}_t can no longer store much informations. Gated RNNs are an elegant modification of vanilla RNNs. One such example is LSTM, in which \\mathbf{h}_t is updated by \\begin{equation}\\begin{split} \\mathbf{c}_t &= \\mathbf{f}_t\\odot \\mathbf{c}_{t-1} + \\mathbf{i}_t\\odot \\tilde{\\mathbf{c}}_t\\\\ \\mathbf{h}_t &= \\mathbf{o}_t\\odot\\tanh(\\mathbf{c}_t) \\end{split}\\end{equation} where \\mathbf{c}_t is the internal state for linear information passing ( \\mathbf{c} is short for memory cell ), {f}_t , \\mathbf{i}_t and \\mathbf{o}_t are three gates used to control the flow of information, \\odot is element-wise production, \\tilde{\\mathbf{c}}_t is the candidate state , which is given by \\tilde{\\mathbf{c}}_t = \\tanh(U_c\\mathbf{h}_{t-1} + W_c\\mathbf{x}_t + \\mathbf{b}_c) The three gates are used in the following manner: forget gate \\mathbf{f}_t controls how much information should be discarded from the previous internal state \\mathbf{c}_{t-1} input gate \\mathbf{i}_t controls how much information should be stored from the candidate state \\tilde{\\mathbf{c}}_t output gate \\mathbf{o}_t controls how much information should be transferred from the internal state \\mathbf{c}_{t} to external state \\mathbf{h}_{t} The values of the three gates are given by \\begin{equation}\\begin{split} \\mathbf{f}_t &= \\sigma(U_f\\mathbf{h}_{t-1} + W_f\\mathbf{x}_t + \\mathbf{b}_f)\\\\ \\mathbf{i}_t &= \\sigma(U_i\\mathbf{h}_{t-1} + W_i\\mathbf{x}_t + \\mathbf{b}_i)\\\\ \\mathbf{o}_t &= \\sigma(U_o\\mathbf{h}_{t-1} + W_o\\mathbf{x}_t + \\mathbf{b}_o) \\end{split}\\end{equation} where \\sigma(\\cdot) is a Logistic function. P.S. In RNNs, \\mathbf{h} stores information about history inputs. In SRNs, \\mathbf{h} is rewritten at every time step t , thus can be perceived as a short-term memory. On the other hand, in LSTM, the memory cell \\mathbf{c} stores history information for some time steps (controlled by forget gate), thus can be seen as a short-term memory that lasts longer than \\mathbf{h} . This is how the name \"Long Short-term Memory\" comes about.","title":"2.2 Long Short-Term Memory (LSTM)"},{"location":"rnn/#23-gated-recurrent-unit-gru","text":"Gated Recurrent Unit is another RNN that uses gating mechanism. However, it does not introduce an extra memory cell. In GRU, \\mathbf{h}_t is updated by \\mathbf{h}_t = \\mathbf{z}_t\\odot\\mathbf{h}_{t-1} + (1-\\mathbf{z}_t)\\odot \\tilde{\\mathbf{h}}_t where \\mathbf{z}_t\\in [0,1] , called update gate, is computed by \\mathbf{z}_t = \\sigma(U_z\\mathbf{h}_{t-1} + W_z\\mathbf{x}_t + \\mathbf{b}_z) and, \\tilde{\\mathbf{h}}_t is computed by \\begin{equation}\\begin{split} \\tilde{\\mathbf{h}}_t &= \\tanh(U_h(\\mathbf{r}_t\\odot\\mathbf{h}_{t-1}) + W_h\\mathbf{x}_t + \\mathbf{b}_h)\\\\ \\mathbf{r}_t &= \\sigma(U_r\\mathbf{h}_{t-1} + W_r\\mathbf{x}_t + \\mathbf{b}_r) \\end{split}\\end{equation} where \\mathbf{r}_t\\in [0,1] , called reset gate, controls how much the candidate state \\tilde{\\mathbf{h}}_t depends on the previous state \\mathbf{h}_{t-1} . Intuitively, the GRU uses only one gate, as opposed to two in LSTM, to control the balance between the operations of forget and input , making it a simpler network than LSTM.","title":"2.3 Gated Recurrent Unit (GRU)"},{"location":"rnn/#3-what-can-rnns-do","text":"What exactly is a recurrent network capable of?","title":"3 What can RNNs do?"},{"location":"rnn/#31-it-can-handle-sequences","text":"A glaring limitation of Vanilla Neural Networks (and also Convolutional Networks) is that their API is too constrained: they accept a fixed-sized vector as input (e.g. an image) and produce a fixed-sized vector as output (e.g. probabilities of different classes). P.S. Vanilla means \"ordinary\" or \"plain\" , not a flavor of dessert. Here it means ordinary neural nets like BPNN, MLP; likewise, vanilla RNNs means ordinary RNNs. The above picture shows some situations for a deep learning system to model. The leftmost subfigure illustrates the situation where both the input and the output are fixed-sized. This can be done without RNNs. The other subfigures show some more common situations, where a system has: sequence output (image captioning), sequence input (text sentiment classification), asynced sequence input and output (machine translation), and synced sequence input and output (POS tagging and NER). RNNs combine the input vector with their state vector with a fixed (but learned) function to produce a new state vector. This can in programming terms be interpreted as running a fixed program with certain inputs and some internal variables. Viewed this way, RNNs essentially describe programs . RNNs are Turing-Complete in the sense that they can to simulate arbitrary programs (with proper weights) . P.S. In Siegelmann and Sontag, 1991 , the authors models a recursive net with continuous-valued neurons as a dynamical system and remark that not only can one simulate a processor net with a Turing machine, but any function computable by a Turing machine can be computed by a processor net. The paper shows that a universal Turing machine can be simulated by a finite neural network made up of sigmoidal neurons. If training vanilla neural nets is optimization over functions, training recurrent nets is optimization over programs.","title":"3.1 It can handle sequences."},{"location":"rnn/#32-it-excels-at-handling-non-sequential-data","text":"Even if the inputs/outputs are fixed vectors, it is still possible to use this powerful formalism to process them in a sequential manner. The following picture illustrates a recurrent network that generates images of digits by learning to sequentially add color to a canvas ( Gregor et al. ) In doing this, you\u2019re learning stateful programs that process your fixed-sized data , as opposed to merely learning a mapping between the input and the output.","title":"3.2 It excels at handling non-sequential data"},{"location":"rnn/#4-conclusion","text":"RNNs are powerful. For further study, please refer to the materials listed at the top of this page.","title":"4 Conclusion"}]}